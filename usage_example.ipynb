{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "In this notebook, We will show the usage of the **GANBLR** models.\n",
    "\n",
    "Currently, the following ganblr models are available in this package:\n",
    "\n",
    "- GANBLR\n",
    "- GANBLR++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GANBLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the data\n",
    "\n",
    "The first step is to get the data we will use. For `GANBLR`, the data must be discrete. \n",
    "\n",
    "In this case, with the built-in `get_demo_data` method, we can get a discrete `adult` data in the format of `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr.utils import get_demo_data\n",
    "\n",
    "df = get_demo_data('adult')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Train the GANBLR Model\n",
    "\n",
    "Next, we will use `sklearn.model_selection.train_test_split` to split the data into training and test sets, then fit the training set into the `GANBLR` model in order to train the model.\n",
    "\n",
    "Note that the `GANBLR` class has build-in `sklearn.preprocessing.OrdinalEncoder` and `sklearn.preprocessing.LabelEncoder` to convert the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#data = OrdinalEncoder(dtype=int).fit_transform(df)\n",
    "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr import GANBLR\n",
    "model = GANBLR()\n",
    "model.fit(X_train, y_train, k = 0, epochs = 10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Generate the synthetic data\n",
    "\n",
    "Once the model is ready, we can use `GANBLR.sample` method to sample some synthetic data.\n",
    "\n",
    "We can use the `size` parameter to specify the number of samples we want to generate. If we do not specify, it will generate the same number as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "\n",
    "syn_data = model.sample(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{type(syn_data)}, {syn_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data = syn_data, columns=df.columns).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. TSTR evaluation\n",
    "\n",
    "Finally, as we did in our paper, we will perform a simple TSTR(Train on Synthetic, Test on Real) evaluation to demonstrate the performance of our generated data.\n",
    "\n",
    "We will evaluate on three models from sklearn, `LogisticRegression`, `RandomForest`, and `MLPClassifier`. \n",
    "\n",
    "TRTR(Train on Real, Test on Real) will be used as the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_lr = model.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = model.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf = model.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lbe = LabelEncoder()\n",
    "X_train_ohe = ohe.fit_transform(X_train)\n",
    "X_test_ohe = ohe.transform(X_test)\n",
    "y_train_lbe = lbe.fit_transform(y_train)\n",
    "y_test_lbe = lbe.transform(y_test)\n",
    "\n",
    "trtr_score_lr  = LogisticRegression().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(X_train, y_train_lbe).score(X_test, y_test_lbe)\n",
    "trtr_score_mlp = MLPClassifier().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', acc_score_lr, acc_score_rf, acc_score_mlp],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP'])\n",
    "df_evaluate\n",
    "#df_evaluate.set_index('Evaluate Item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GANBLR++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr import GANBLRPP\n",
    "from pandas import DataFrame, read_csv\n",
    "df = read_csv('../uci-datasets/raw_csv/adult.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numerical_columns = np.argwhere(df.dtypes.values == float).ravel()\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganblrpp = GANBLRPP(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = df.values[:,:-1], df.values[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganblrpp._GANBLRPP__discritizer._DMMDiscritizer__arr_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(mu) for mu in ganblrpp._GANBLRPP__discritizer._DMMDiscritizer__arr_mu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmmd = ganblrpp._GANBLRPP__discritizer\n",
    "x = dmmd._DMMDiscritizer__scaler.fit_transform(X_train[:,numerical_columns])\n",
    "print(x.shape)\n",
    "arr_modes = []\n",
    "for i, dmm in enumerate(dmmd._DMMDiscritizer__dmms):\n",
    "    cur = x[:,i:i+1]\n",
    "    print(cur.shape)\n",
    "    modes = dmm.predict(cur)\n",
    "    modes = LabelEncoder().fit_transform(modes)#.astype(int)\n",
    "    arr_modes.append(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganblrpp.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_lr  = ganblrpp.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = ganblrpp.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf  = ganblrpp.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [0,1,2,3]\n",
    "catgorical_columns = np.argwhere([col not in numerical_columns for col in range(8)])\n",
    "list(set(range(8)) - set(numerical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "eval_model = None\n",
    "if model=='lr':\n",
    "    eval_model = LogisticRegression() \n",
    "elif model == 'rf':\n",
    "    eval_model = RandomForestClassifier()\n",
    "elif model == 'mlp':\n",
    "    eval_model = MLPClassifier() \n",
    "elif hasattr(model, 'fit'):\n",
    "    eval_model = model\n",
    "else:\n",
    "    raise Exception('Invalid Arugument')\n",
    "    \n",
    "synthetic_data = ganblrpp.sample()\n",
    "synthetic_x, synthetic_y = synthetic_data[:,:-1], synthetic_data[:,-1]\n",
    "\n",
    "numerical_columns = ganblrpp._numerical_columns\n",
    "catgorical_columns = list(set(range(x.shape[1])) - set(numerical_columns))\n",
    "ode = OrdinalEncoder(categories=ganblrpp._GANBLRPP__ganblr._d.get_categories(catgorical_columns))\n",
    "ohe = OneHotEncoder(categories =ganblrpp._GANBLRPP__ganblr._d.get_categories(catgorical_columns), sparse=False)\n",
    "lbe = ganblrpp._GANBLRPP__ganblr._label_encoder\n",
    "scaler = StandardScaler()\n",
    " \n",
    "real_x_num = scaler.fit_transform(X_test[:,numerical_columns])\n",
    "syn_x_num  = scaler.fit_transform(synthetic_x[:,numerical_columns])\n",
    "if model != 'rf':\n",
    "    real_x_cat = ohe.fit_transform(X_test[:,catgorical_columns])\n",
    "    syn_x_cat  = ohe.fit_transform(synthetic_x[:,catgorical_columns])\n",
    "else:\n",
    "    real_x_cat = x[:,catgorical_columns]\n",
    "    syn_x_cat = synthetic_x[:,catgorical_columns]\n",
    " \n",
    "real_y = lbe.transform(y)\n",
    "syn_y  = lbe.transform(synthetic_y)\n",
    "\n",
    "eval_model.fit(np.hstack([syn_x_num, syn_x_cat]), syn_y)\n",
    "pred = eval_model.predict(np.hstack([real_x_num, real_x_cat]))\n",
    "acc = accuracy_score(real_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbedb5fa720de9fc907ceb56d89ea952339fe8fd12ba55975f895c345e9c974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
